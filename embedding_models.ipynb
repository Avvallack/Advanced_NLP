{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from embedding.data_load import DATA_FRAME\n",
    "from embedding.data_preparation import build_vocab, create_index_frame\n",
    "from embedding.embedding_model import initialize_embedding, train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(DATA_FRAME['clean_tags'], DATA_FRAME['clean_title'], min_frequency=100)\n",
    "index_df = create_index_frame(vocab, DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_matrix = initialize_embedding(vocab, dimension=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d534de2e23664ec3b9323eac31abebc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 R@5 = 49.75%\n",
      "epoch = 1 R@5 = 53.02%\n",
      "epoch = 2 R@5 = 56.48%\n",
      "epoch = 3 R@5 = 59.68%\n",
      "epoch = 4 R@5 = 52.75%\n",
      "epoch = 5 R@5 = 51.57%\n",
      "epoch = 6 R@5 = 64.22%\n",
      "epoch = 7 R@5 = 49.65%\n",
      "epoch = 8 R@5 = 62.70%\n",
      "epoch = 9 R@5 = 52.85%\n",
      "epoch = 10 R@5 = 61.04%\n",
      "epoch = 11 R@5 = 55.02%\n",
      "Best metric is: 64.22%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_embeddings = train_embeddings(index_df, \n",
    "                                      initial_matrix, \n",
    "                                      vector_method='avg', \n",
    "                                      descent_type='rmsprop', \n",
    "                                      num_iterations=50,\n",
    "                                      update_rate=0.75,\n",
    "                                      learning_rate=1e-2, \n",
    "                                     dele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reactjs', 'js', 'react', 'redux', 'react_dot_js']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"react\"\n",
    "token_id = vocab[token]\n",
    "back_vocab = {item: key for key, item in vocab.items()}\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['нейронные сети', 'машинное обучение', 'ml', 'машинное', 'machine learning']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"машинное обучение\"\n",
    "token_id = vocab[token]\n",
    "back_vocab = {item: key for key, item in vocab.items()}\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['последнюю', 'angular', 'react', 'фронтенда', 'frontend']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"angular\"\n",
    "token_id = vocab[token]\n",
    "back_vocab = {item: key for key, item in vocab.items()}\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google chrome', 'браузеры', 'браузера', 'chrome', 'firefox']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"chrome\"\n",
    "token_id = vocab[token]\n",
    "back_vocab = {item: key for key, item in vocab.items()}\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding.data_load import TEXT_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_texts = build_vocab(TEXT_FRAME['clean_title'], TEXT_FRAME['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = create_index_frame(vocab_texts, TEXT_FRAME, train_col='clean_text', target_col='clean_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_matrix = initialize_embedding(vocab_texts, dimension=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5badb178e48419391e626f6ae48b52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 R@5 = 45.72%\n",
      "epoch = 1 R@5 = 51.26%\n",
      "epoch = 2 R@5 = 51.71%\n",
      "epoch = 3 R@5 = 34.67%\n",
      "epoch = 4 R@5 = 43.76%\n",
      "epoch = 5 R@5 = 43.68%\n",
      "epoch = 6 R@5 = 40.00%\n",
      "epoch = 7 R@5 = 50.52%\n",
      "Best metric is: 51.71%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_embeddings = train_embeddings(text_df, \n",
    "                                      initial_matrix, \n",
    "                                      vector_method='avg', \n",
    "                                      descent_type='rmsprop',\n",
    "                                      learning_rate=0.05,\n",
    "                                      update_rate=0.8, \n",
    "                                      num_iterations=50, \n",
    "                                      target_col='clean_title', \n",
    "                                      train_col='clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mozilla', 'браузера', 'браузер', 'firefox', 'chrome']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"firefox\"\n",
    "token_id = vocab_texts[token]\n",
    "back_vocab = {item: key for key, item in vocab_texts.items()}\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'обучения', 'обучение', 'ml', 'ии']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"ml\"\n",
    "token_id = vocab_texts[token]\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['react', 'javascript', 'ios', 'css', 'js']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"react\"\n",
    "token_id = vocab_texts[token]\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['javascript', 'angular', 'css', 'react', 'js']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"angular\"\n",
    "token_id = vocab_texts[token]\n",
    "[back_vocab[i] for i in np.argpartition(-(trained_embeddings @ trained_embeddings[token_id]), 5)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
